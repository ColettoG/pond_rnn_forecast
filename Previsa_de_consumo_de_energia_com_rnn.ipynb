{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u1gn3yPlzooW"
      },
      "source": [
        "# Previsão de Consumo de Energia com RNN (LSTM)\n",
        "\n",
        "Este notebook demonstra como usar **Redes Neurais Recorrentes (RNN)**, especificamente uma camada **LSTM**,\n",
        "para prever o consumo de energia ativa (`Global_active_power`) em uma residência,\n",
        "usando o dataset **Household Electric Power Consumption** disponível no Kaggle/UCI.\n",
        "\n",
        "---\n",
        "\n",
        "## 1. Descrição do Dataset\n",
        "\n",
        "O dataset contém medições de consumo elétrico de uma residência em intervalos de 1 minuto ao longo de ~4 anos.  \n",
        "As colunas principais são:\n",
        "\n",
        "- **Date/Time**: Data e hora da medição.  \n",
        "- **Global_active_power**: Potência ativa global (kW).  \n",
        "- **Global_reactive_power**: Potência reativa global (kW).  \n",
        "- **Voltage**: Voltagem (V).  \n",
        "- **Global_intensity**: Corrente elétrica (A).  \n",
        "- **Sub_metering_1**: Consumo da cozinha (Wh).  \n",
        "- **Sub_metering_2**: Consumo da lavanderia (Wh).  \n",
        "- **Sub_metering_3**: Consumo do aquecedor/ar-condicionado (Wh).  \n",
        "\n",
        "---\n",
        "\n",
        "## 2. Métrica de Avaliação\n",
        "\n",
        "Escolhemos a **RMSE (Root Mean Squared Error)**.  \n",
        "\n",
        "- Mede o erro médio entre valores previstos e reais.  \n",
        "- Penaliza erros grandes mais fortemente do que o MAE.  \n",
        "- É útil em séries temporais de energia, onde picos de consumo são importantes e devem ser previstos com precisão.  \n",
        "- A unidade é a mesma da variável prevista (kW), o que facilita a interpretação.  \n",
        "\n",
        "---\n",
        "\n",
        "## 3. Pipeline de Modelagem\n",
        "\n",
        "1. **Pré-processamento**  \n",
        "   - Carregar o dataset.  \n",
        "   - Unir as colunas `Date` e `Time` em um índice temporal.  \n",
        "   - Tratar valores ausentes e converter para amostras horárias.  \n",
        "\n",
        "2. **Transformação em formato supervisionado**  \n",
        "   - Usar as últimas 24 horas de consumo (`Global_active_power`) para prever a próxima hora.  \n",
        "\n",
        "3. **Divisão em treino e teste**  \n",
        "   - 80% para treino, 20% para teste.  \n",
        "\n",
        "4. **Modelo RNN (LSTM)**  \n",
        "   - Camada LSTM com 50 unidades.  \n",
        "   - Camada densa de saída.  \n",
        "\n",
        "5. **Treinamento e avaliação**  \n",
        "   - Função de perda: MSE.  \n",
        "   - Métrica final: RMSE no conjunto de teste.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wOQY8A7Mznvz",
        "outputId": "f543fd06-6c36-4ffc-9ba3-95407670b70e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-4064104951.py:11: FutureWarning: Support for nested sequences for 'parse_dates' in pd.read_csv is deprecated. Combine the desired columns with pd.to_datetime after parsing instead.\n",
            "  data = pd.read_csv(\n",
            "/tmp/ipython-input-4064104951.py:11: FutureWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
            "  data = pd.read_csv(\n",
            "/tmp/ipython-input-4064104951.py:25: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  data = data.resample(\"H\").mean().ffill()  # usar média por hora e preencher faltantes\n"
          ]
        }
      ],
      "source": [
        "# ==============================\n",
        "# 1. Imports e Carregamento de Dados\n",
        "# ==============================\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense\n",
        "\n",
        "# Carregar dataset (baixado do Kaggle/UCI)\n",
        "# O arquivo original vem como .txt separado por \";\"\n",
        "data = pd.read_csv(\n",
        "    \"/content/household_power_consumption.txt\", # atualizar o caminho para rodar localmente (testado no colab)\n",
        "    sep=\";\",\n",
        "    parse_dates={\"Datetime\": [\"Date\", \"Time\"]},\n",
        "    dayfirst=True,\n",
        "    infer_datetime_format=True,\n",
        "    na_values=[\"?\"]\n",
        ")\n",
        "\n",
        "# Definir índice como datetime\n",
        "data.set_index(\"Datetime\", inplace=True)\n",
        "\n",
        "# Converter para valores numéricos e preencher faltantes\n",
        "data = data.apply(pd.to_numeric, errors=\"coerce\")\n",
        "data = data.resample(\"H\").mean().ffill()  # usar média por hora e preencher faltantes\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dWqnUM1SzyIz"
      },
      "source": [
        "## 4. Criação do Conjunto Supervisionado\n",
        "\n",
        "Para prever o próximo valor, usamos uma janela deslizante:  \n",
        "- **Entrada (X):** valores das últimas 24 horas.  \n",
        "- **Saída (y):** valor da 25ª hora (próxima).  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NLu7bwPIzznZ",
        "outputId": "3e41e044-e71e-418e-c72f-399a8dec7ad5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Formato dos dados: (27652, 24, 1) (27652,) (6913, 24, 1) (6913,)\n"
          ]
        }
      ],
      "source": [
        "# ==============================\n",
        "# 2. Função para criar dataset supervisionado\n",
        "# ==============================\n",
        "def create_dataset(series, n_lag=24):\n",
        "    X, y = [], []\n",
        "    for i in range(len(series) - n_lag):\n",
        "        X.append(series[i:(i + n_lag)])\n",
        "        y.append(series[i + n_lag])\n",
        "    return np.array(X), np.array(y)\n",
        "\n",
        "# Usar apenas a variável alvo: Global_active_power\n",
        "series = data[\"Global_active_power\"].values\n",
        "\n",
        "n_lag = 24  # usar 24 horas passadas\n",
        "X, y = create_dataset(series, n_lag)\n",
        "\n",
        "# Ajustar formato para RNN (samples, timesteps, features)\n",
        "X = X.reshape((X.shape[0], X.shape[1], 1))\n",
        "\n",
        "# Divisão treino/teste\n",
        "split = int(len(X) * 0.8)\n",
        "X_train, X_test = X[:split], X[split:]\n",
        "y_train, y_test = y[:split], y[split:]\n",
        "\n",
        "print(\"Formato dos dados:\", X_train.shape, y_train.shape, X_test.shape, y_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MbId9nKCz2Dd"
      },
      "source": [
        "## 5. Construção do Modelo LSTM\n",
        "\n",
        "Criamos um modelo simples com:\n",
        "- Uma camada **LSTM** com 50 unidades.  \n",
        "- Uma camada densa final com 1 neurônio (previsão).  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SHAJ2qxUz49n",
        "outputId": "595beca3-8565-45c3-a6b4-0c62510695da"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/rnn/rnn.py:199: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "385/385 - 6s - 15ms/step - loss: 0.5222 - val_loss: 0.2777\n",
            "Epoch 2/10\n",
            "385/385 - 2s - 4ms/step - loss: 0.3848 - val_loss: 0.2656\n",
            "Epoch 3/10\n",
            "385/385 - 3s - 7ms/step - loss: 0.3723 - val_loss: 0.2593\n",
            "Epoch 4/10\n",
            "385/385 - 2s - 5ms/step - loss: 0.3652 - val_loss: 0.2706\n",
            "Epoch 5/10\n",
            "385/385 - 2s - 4ms/step - loss: 0.3658 - val_loss: 0.2684\n",
            "Epoch 6/10\n",
            "385/385 - 2s - 4ms/step - loss: 0.3600 - val_loss: 0.2579\n",
            "Epoch 7/10\n",
            "385/385 - 2s - 4ms/step - loss: 0.3615 - val_loss: 0.2523\n",
            "Epoch 8/10\n",
            "385/385 - 2s - 4ms/step - loss: 0.3571 - val_loss: 0.2550\n",
            "Epoch 9/10\n",
            "385/385 - 2s - 4ms/step - loss: 0.3557 - val_loss: 0.2559\n",
            "Epoch 10/10\n",
            "385/385 - 2s - 4ms/step - loss: 0.3556 - val_loss: 0.2541\n"
          ]
        }
      ],
      "source": [
        "# ==============================\n",
        "# 3. Modelo RNN LSTM\n",
        "# ==============================\n",
        "model = Sequential()\n",
        "model.add(LSTM(50, activation=\"relu\", input_shape=(n_lag, 1)))\n",
        "model.add(Dense(1))\n",
        "\n",
        "model.compile(optimizer=\"adam\", loss=\"mse\")\n",
        "\n",
        "# Treinar modelo\n",
        "history = model.fit(\n",
        "    X_train, y_train,\n",
        "    epochs=10,\n",
        "    batch_size=72,\n",
        "    validation_data=(X_test, y_test),\n",
        "    verbose=2\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b_uXxv1A0E1q"
      },
      "source": [
        "## 6. Avaliação do Modelo\n",
        "\n",
        "Após o treinamento, calculamos o **RMSE** no conjunto de teste."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k-7rx3cez_oF",
        "outputId": "683689e1-69db-4573-92f1-34d6b0dcaba5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m217/217\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step\n",
            "RMSE no conjunto de teste: 0.504 kW\n"
          ]
        }
      ],
      "source": [
        "# ==============================\n",
        "# 4. Avaliação do Modelo\n",
        "# ==============================\n",
        "preds = model.predict(X_test)\n",
        "\n",
        "mse = np.mean((preds.flatten() - y_test) ** 2)\n",
        "rmse = np.sqrt(mse)\n",
        "\n",
        "print(f\"RMSE no conjunto de teste: {rmse:.3f} kW\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "neptn9990AnA"
      },
      "source": [
        "## 7. Conclusão\n",
        "\n",
        "- O modelo **LSTM** foi capaz de aprender padrões temporais do consumo de energia.  \n",
        "- O valor de **RMSE** mostra o erro médio da previsão em kW.  \n",
        "- Este pipeline pode ser expandido para usar múltiplas variáveis (multivariado), diferentes janelas de tempo,\n",
        "ou arquiteturas mais complexas (Stacked LSTM, GRU, etc.).  "
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
